{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook is for experimenting with the open graph benchmarks(ogb) node prediction tasks.\n",
    "* It contains the following modules\n",
    "    * analysis-does simple eda\n",
    "    * create_dataloader- creates a train valid and test dataloader\n",
    "    * Gat- GatConv layers.\n",
    "    * one_epoch- trains model for one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data.sampler import NeighborSampler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader/analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=PygNodePropPredDataset(name='ogbn-arxiv',root='../node_dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = dataset.get_idx_split()\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.10.1'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(data,split_idx:dict,name:str):\n",
    "    if name=='ogbn-arxiv' or name=='ogbn-products':\n",
    "        print(f'output analysis {name}')\n",
    "        for i in ['train','valid','test']:\n",
    "            figure=plt.figure(figsize=(10,3))\n",
    "            sns.countplot(x=data.y[split_idx[i]].squeeze(1).numpy())\n",
    "            plt.title(f'{i} y')\n",
    "            plt.show()\n",
    "    return data\n",
    "\n",
    "def preprocess(data,split_idx:dict,name:str):\n",
    "    '''\n",
    "    Normalize node features.\n",
    "    preprocess dataset based on name.\n",
    "    --args--\n",
    "    data=PygNodePropPredDataset(name)[0]\n",
    "    name: name of ogbn dataset.\n",
    "    '''\n",
    "    print(f'preprocessing {name}')\n",
    "    if name=='ogbn-arxiv':\n",
    "        #add directed edge in other direction\n",
    "        #add edge attribute\n",
    "        print('adding edges in other direction')\n",
    "        print('normalizing')\n",
    "    elif name=='ogbn-products':\n",
    "        print('normalizing')\n",
    "    return data\n",
    "\n",
    "def create_dataloder(data,split_idx:dict,sizes=[-1,-1,-1],batch_size=2048)->dict:\n",
    "    '''\n",
    "    return train,test and valid dataloaders in a dict.\n",
    "    --args--\n",
    "    data=PygNodePropPredDataset(name)[0]\n",
    "    split_idx: is a dictonary with train,valid and test ids. output of get_idx_split \n",
    "    '''\n",
    "    loader_dict={}\n",
    "    train_batchsize=batch_size\n",
    "    for i in ['train','valid','test']:\n",
    "        idx=split_idx[i]\n",
    "        batch_size=train_batchsize if i=='train' else 2*train_batchsize\n",
    "        shuffle=True if i=='train' else False\n",
    "        loader=NeighborSampler(data.edge_index,node_idx=idx,sizes=sizes, batch_size=batch_size,\n",
    "                               shuffle=shuffle)\n",
    "        loader_dict[i]=loader\n",
    "    return loader_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=2048\n",
    "loader=create_dataloder(data,split_idx,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric.nn import GATConv,BatchNorm\n",
    "from torch import nn,optim\n",
    "class Gat(nn.Module):\n",
    "    def __init__(self,inp_dim=3,filters=[16,16,16],drop=0.1,edge_drop=0.1,bn=True):\n",
    "        super().__init__()#all params are added to _modules internally, this makes sure its initialized.\n",
    "        self.gat_modules=nn.ModuleList()\n",
    "        self.bn=bn\n",
    "        self.bn_modules=nn.ModuleList()\n",
    "        for i,j in enumerate(filters):\n",
    "            if i==0:\n",
    "                self.gat_modules.append(GATConv(in_channels=inp_dim,out_channels=filters[i],dropout=edge_drop))\n",
    "            else:\n",
    "                self.gat_modules.append(GATConv(in_channels=filters[i-1],out_channels=filters[i],dropout=edge_drop))\n",
    "            \n",
    "            if bn:\n",
    "                self.bn_modules.append(BatchNorm(in_channels=filters[i]))\n",
    "        self.leaky=nn.LeakyReLU()\n",
    "        self.drop=nn.Dropout(p=edge_drop)\n",
    "    \n",
    "    def forward(self,x,adjs):\n",
    "        for i,adj in enumerate(adjs):\n",
    "            x=self.gat_modules[i](x,adj.edge_index.to(device=x.device))\n",
    "            x=x[:adj.size[1]]\n",
    "            x=self.leaky(x)\n",
    "            if self.bn:\n",
    "                x=self.bn_modules[i](x)\n",
    "            x=self.drop(x)\n",
    "        return x\n",
    "class Fcn(nn.Module):\n",
    "    '''\n",
    "    last layer will not have activation.\n",
    "    '''\n",
    "    def __init__(self,inp_dim=16,layers=[8,40],bn=True,drop=0.1):\n",
    "        super().__init__()\n",
    "        self.lyrs=[]\n",
    "        for i,j in enumerate(layers):\n",
    "            if i==0:\n",
    "                self.lyrs.append(nn.Linear(inp_dim,layers[i]))\n",
    "            else:\n",
    "                self.lyrs.append(nn.Linear(layers[i-1],layers[i]))\n",
    "            if i!=len(layers)-1:\n",
    "                self.lyrs.append(nn.LeakyReLU())\n",
    "                self.lyrs.append(nn.BatchNorm1d(layers[i]))\n",
    "                self.lyrs.append(nn.Dropout(p=drop))\n",
    "        self.lyrs=nn.Sequential(*self.lyrs)#pass the list to Sequential.   \n",
    "    def forward(self,x):\n",
    "        return self.lyrs(x)\n",
    "\n",
    "class arxiv_classifier(nn.Module):\n",
    "    def __init__(self,gnn_inp_dim=3,gnn_filters=[16,16,16],gnn_drop=0.1,gnn_edge_drop=0.1,gnn_bn=True\n",
    "                ,fc_inp_dim=16,fc_layers=[8,40],fc_bn=True,fc_drop=0.1):\n",
    "        super().__init__()\n",
    "        self.gnn=Gat(inp_dim=gnn_inp_dim,filters=gnn_filters,drop=gnn_drop,\n",
    "                     edge_drop=gnn_edge_drop,bn=gnn_bn)\n",
    "        self.fcn=Fcn(inp_dim=fc_inp_dim,layers=fc_layers,bn=fc_bn,drop=fc_drop)\n",
    "    def forward(self,x,adjs):\n",
    "        gnn_out=self.gnn(x,adjs)\n",
    "        return self.fcn(gnn_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model=arxiv_classifier(gnn_inp_dim=128)\n",
    "model=model.to(device=device)\n",
    "opt=optim.Adam(model.parameters(),lr=0.05)\n",
    "scheduler=optim.lr_scheduler.CyclicLR(optimizer=opt,base_lr=0.01,max_lr=0.1,step_size_up=100,cycle_momentum=False)\n",
    "closs=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4594113896439478\n",
      "0.5081714151481593\n",
      "0.5431725896842176\n",
      "0.5412262156448203\n",
      "0.5379039565086077\n",
      "0.5406557267022384\n",
      "0.5525353199771804\n",
      "0.5384744454511896\n",
      "0.5348166045840465\n",
      "0.5599181180576529\n"
     ]
    }
   ],
   "source": [
    "def accuracy(pred:torch.tensor,truth:torch.tensor):\n",
    "    return sum(pred==truth).item()/len(truth)\n",
    "def one_epoch(data,loader,model,loss_func,opt,eval_func=accuracy,train=True):\n",
    "    sum_eval=0\n",
    "    datapoints=0\n",
    "    for size,n_id,adjs in loader:\n",
    "        inp=data.x[n_id].to(device=device)\n",
    "        pred=model(inp,adjs)\n",
    "        truth=data.y[n_id[:size]].to(device=device).squeeze(dim=1)\n",
    "        loss=loss_func(pred,truth)\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        sum_eval+=accuracy(torch.argmax(pred,dim=1),truth)*size#.item converts a 0d tensor to a python number \n",
    "        datapoints+=size\n",
    "    return sum_eval/datapoints\n",
    "        \n",
    "epochs=10\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    train_loss=one_epoch(data,loader['train'],model,closs,opt)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss=one_epoch(data,loader['valid'],model,closs,opt,train=False)\n",
    "    print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
